---
title: "Resident Production Model"
author: "Caliper Corporation"
date: "March 2, 2021"
output: 
  html_document:
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(dplyr.summarise.inform = FALSE)
options(scipen = 999)

library(MASS)
library(pscl)
library(tidyverse)
library(knitr)
library(kableExtra)
```

## Introduction

Zero-Inflated Negative Binomial Distribution:  
[https://stats.idre.ucla.edu/r/dae/zinb/](https://stats.idre.ucla.edu/r/dae/zinb/)

> Zero-inflated negative binomial regression is for modeling count variables with excessive zeros and it is usually for overdispersed count outcome variables. Furthermore, theory suggests that the excess zeros are generated by a separate process from the count values and that the excess zeros can be modeled independently.

```{r, include=FALSE}
hh_df <- read_csv("data/output/_PRIVATE/survey_processing/hh_processed.csv")
person_df <- read_csv("data/output/_PRIVATE/survey_processing/per_processed.csv")
trips_df <- read_csv("data/output/_PRIVATE/survey_processing/trips_processed.csv")
logsum <- read_csv("data/input/nhb/logsums.csv")
```

```{r aggregate trips}
# # Approach 1: use trip weights. Have non-integer counts of trips.
# aggregate_trips <- trips_df %>%
#   filter(tour_type != "H" & homebased == "HB") %>%
#   group_by(hhid, personid, trip_type) %>%
#   summarize(trips = sum(trip_weight_combined) / sum(hh_weight_combined)) %>%
#   pivot_wider(names_from = trip_type, values_from = trips) %>%
#   mutate(across(everything(), ~ifelse(is.na(.x), 0, .x)))

# Approach 2: use household weights and have integer counts of trips.
aggregate_trips <- trips_df %>%
  filter(tour_type != "H" & homebased == "HB") %>%
  group_by(hhid, personid, trip_type) %>%
  summarize(
    trips = n(),
    p_taz = first(p_taz)
  ) %>%
  pivot_wider(names_from = trip_type, values_from = trips) %>%
  mutate(across(everything(), ~ifelse(is.na(.x), 0, .x))) %>%
  ungroup()

est_tbl <- person_df %>%
  left_join(aggregate_trips %>% select(-hhid), by = "personid") %>%
  left_join(hh_df, by = "hhid") %>%
  mutate(across(N_HB_K12_All:W_HB_EK12_All, ~ifelse(is.na(.x), 0, .x))) %>%
  # feature creation
  mutate(
    weight = hh_weight_combined.x,
    oth_ppl = hhsize - 1,
    oth_wrkr = num_workers - is_worker,
    oth_senior = num_seniors - is_senior,
    oth_kids = num_children - is_child,
    N_HB_K12_All = as.integer(N_HB_K12_All)
  ) %>%
  left_join(
    logsum %>% select(TAZ, access = GeneralAccessibility_sov),
    by = c("p_taz" = "TAZ")
  ) %>%
  group_by(hhid) %>%
  mutate(access = ifelse(is.na(access), mean(access, na.rm = TRUE), access)) %>%
  ungroup() %>%
  mutate(access = ifelse(is.na(access), mean(access, na.rm = TRUE), access))
```

The chart below is a histogram of person trips observed in the Triangle survey.
The occasional odd number of trips is due to things like leaving the region
or having a trip leave home late in the evening and the return trip isn't until
the next day (and not in the survey).

```{r}
hist_tbl <- est_tbl %>%
  mutate(
    trips = select(., N_HB_K12_All:W_HB_EK12_All) %>% rowSums(na.rm = TRUE))

ggplot(hist_tbl, aes(x = trips)) +
  geom_histogram(bins = 15, fill = "blue") +
  labs(
    title = "Histogram of Person Trips",
    x = "Trips",
    y = "Count"
  ) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(breaks = seq(0, 15, by = 1))
```


```{r, N_HB_K12_All}
formula <- N_HB_K12_All ~ is_child + is_worker + is_senior + num_vehicles + 
  hhsize + access
m0 <- glm(formula, family = poisson, data = est_tbl)
m1 <- glm.nb(
  formula,
  data = est_tbl
)
m2 <- zeroinfl(
  N_HB_K12_All ~ is_worker + is_senior + num_vehicles + hhsize + oth_kids +
    access | is_child,
  data = est_tbl, dist = "negbin"#, weights = weight
)

# This suggests that the negative binomial is much better than the poisson
# pchisq(2 * (logLik(m1) - logLik(m0)), df = 1, lower.tail = FALSE)

# This shows that the zero-inflated neg binomial is better than the neg binomial
# vuong(m1, m2)

summary(m2)
pR2(m2)
```

```{r, N_HB_OME_All}
m2 <- zeroinfl(
  N_HB_OME_All ~ is_senior + num_vehicles + oth_ppl + oth_kids +
    access + oth_senior | oth_ppl + num_seniors + num_children,
  data = est_tbl, dist = "negbin"#, weights = weight
)

summary(m2)
pR2(m2)
cor(est_tbl$N_HB_OME_All, m2$fitted.values) ^ 2

plot(est_tbl$N_HB_OME_All, m2$fitted.values)
```

```{r}
# install.packages("mlr-org/mlr3")
# install.packages("xgboost")
# install.packages("parallelMap")
library(mlr)
library(parallelMap)
library(plotly)

# Feature creation
dt_tbl <- est_tbl %>%
  select(N_HB_OME_All, is_senior, num_vehicles, oth_ppl, oth_kids, oth_senior, num_seniors, num_children, access) %>%
  mutate(N_HB_OME_All = ifelse(N_HB_OME_All > 1, 1, N_HB_OME_All)) %>%
  mutate(across(N_HB_OME_All:num_children, as.factor)) %>%
  normalizeFeatures(target = "N_HB_OME_All") %>%
  createDummyFeatures(
    target = "N_HB_OME_All",
    cols = c(
      "is_senior",
      "num_vehicles",
      "oth_ppl",
      "oth_kids",
      "oth_senior",
      "num_seniors",
      "num_children"
    )
  ) %>%
  mutate(
    id = seq(1, n(), 1),
    weight = est_tbl$weight
  )

# Split into train/test data
test_set <- dt_tbl %>% sample_n(.10 * nrow(dt_tbl))
test_weights <- test_set$weight
train_set <- dt_tbl[!dt_tbl$id %in% test_set$id, ]
train_weights <- train_set$weight
test_set <- test_set %>% select(-id, -weight)
train_set <- train_set %>% select(-id, -weight)

# Create tasks
# trainTask <- makeClassifTask(data = train_set, target = "N_HB_OME_All", weights = train_weights)
trainTask <- makeClassifTask(data = train_set, target = "N_HB_OME_All")
# testTask <- makeClassifTask(data = test_set, target = "N_HB_OME_All", weights = test_weights)
testTask <- makeClassifTask(data = test_set, target = "N_HB_OME_All")

# The classes are imbalanced with 0 being the dominant class. Use oversampling.
# table(getTaskTargets(trainTask))
trainTask <- oversample(trainTask, rate = 2)
```

```{r create-fit-tune xgboost, eval=FALSE}
# Create learner
xgb_learner <- makeLearner(
  "classif.xgboost",
  # predict.type = "prob",
  predict.type = "response",
  par.vals = list(
    # mlr folks noted bug when objective is included (issue created). remove.
    # objective = "multi:softmax",
    # eval_metric = "merror"
    eval_metric = "error"
  )
)

# Make a hyper-parameter set for tuning
xgb_params <- makeParamSet(
  # The number of trees in the model (each one built sequentially)
  makeIntegerParam("nrounds", lower = 50, upper = 250),
  # number of splits in each tree
  makeIntegerParam("max_depth", lower = 1, upper = 5),
  # "shrinkage" - prevents overfitting
  makeNumericParam("eta", lower = .1, upper = .5),
  # L2 regularization - prevents overfitting
  makeNumericParam("lambda", lower = -1, upper = 0, trafo = function(x) 10^x)
)

# Create a control for searching the hyper-parameter space
control <- makeTuneControlRandom(maxit = 10)

# Create a resampling plan
resample_desc <- makeResampleDesc("CV", iters = 10)

# Tune the hyper-parameters
parallelStartMulticore(8)
tuned_params <- tuneParams(
  learner = xgb_learner,
  task = trainTask,
  resampling = resample_desc,
  par.set = xgb_params,
  control = control
)
parallelStop()

# Create a new learner using the tuned hyper-parameters
xgb_learner_tuned <- setHyperPars(
  learner = xgb_learner,
  par.vals = tuned_params$x
)

# Create model
xgb_model <- train(xgb_learner_tuned, task = trainTask)

# Save the model so that this chunk does not have to be evaluated every
# time the page is knit.
saveRDS(xgb_model, "xgb_model.RDS")
```

```{r load xgboost model}
xgb_model <- readRDS("xgb_model.RDS")
```

```{r feature importance}
# Show feature importance
imp_tbl <- getFeatureImportance(xgb_model)
imp_tbl <- imp_tbl$res #%>%
  # gather(key = "Feature", value = "Importance") %>%
  # arrange(Importance)

# plot_ly() %>%
#   add_trace(
#     data = imp_tbl, y = ~Feature, x = ~Importance, type = "bar",
#     orientation = "h"
#   ) %>%
#   layout(margin = list(l = 110))

plot_ly() %>%
  add_trace(
    data = imp_tbl, y = ~variable, x = ~importance, type = "bar",
    orientation = "h"
  ) %>%
  layout(margin = list(l = 110))

# Make prediction on test data set. Importantly, this will return
# the probabilities as well as set the class the the one with highest
# probability. Ignore that 
xgb_result <- predict(xgb_model, testTask)

# Also get confusion matrix
conf_mtx <- calculateConfusionMatrix(xgb_result)
```